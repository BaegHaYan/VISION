{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fd8ffb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eab80a6",
   "metadata": {},
   "source": [
    "'''\n",
    "{'filename': '5f656a0f627a3ef96dec882437e3e7ada1c7a877201cf54dcd7a2c4508588ff3_여_30_기쁨_공공시설&종교&의료시설_20201204105732-001-007.jpg',\n",
    " 'gender': '여',\n",
    " 'age': 30,\n",
    " 'isProf': '전문인',\n",
    " 'faceExp_uploader': '기쁨',\n",
    " 'bg_uploader': '공공시설/종교/의료시설',\n",
    " 'annot_A': {'boxes': {'maxX': 1912.2253,\n",
    "   'maxY': 1581.6027,\n",
    "   'minX': 1187.4949,\n",
    "   'minY': 579.22235},\n",
    "  'faceExp': '기쁨',\n",
    "  'bg': '공공시설/종교/의료'},\n",
    " 'annot_B': {'boxes': {'maxX': 1912.348108621648,\n",
    "   'maxY': 1572.1522585800617,\n",
    "   'minX': 1206.363701502596,\n",
    "   'minY': 579.1777983055337},\n",
    "  'faceExp': '기쁨',\n",
    "  'bg': '공공시설/종교/의료'},\n",
    " 'annot_C': {'boxes': {'maxX': 1890.909447114109,\n",
    "   'maxY': 1567.448627450284,\n",
    "   'minX': 1183.8414475546967,\n",
    "   'minY': 596.9434661684523},\n",
    "  'faceExp': '기쁨',\n",
    "  'bg': '공공시설/종교/의료'}}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf704aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaegDataset(Dataset):\n",
    "    def __init__(self ,mode = 'train', transform = None):\n",
    "        self.mode = mode\n",
    "        # image dataset\n",
    "        # image dataset 병합\n",
    "        upset_list = glob(\"/data/Emotion_data/Training/upset/*\")\n",
    "        pleasure_list = glob(\"/data/Emotion_data/Training/pleasure/*\")\n",
    "        hurt_list = glob(\"/data/Emotion_data/Training/hurt/*\")\n",
    "        anger_list = glob(\"/data/Emotion_data/Training/anger/*\")\n",
    "        unrest_list = glob(\"/data/Emotion_data/Training/unrest/*\")\n",
    "        sad_list = glob(\"/data/Emotion_data/Training/sad/*\")\n",
    "        neutrality_list = glob(\"/data/Emotion_data/Training/neutrality/*\")\n",
    "        self.data_list = upset_list + pleasure_list + anger_list + unrest_list + sad_list + neutrality_list\n",
    "        \n",
    "        # json dataset\n",
    "        self.label_list = glob(\"/data/Emotion_data/Training/label/*\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # load images and mask\n",
    "        img_path = self.data_list[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img = np.array(img, np.float32)\n",
    "        \n",
    "        label = \n",
    "        if self.transform  is not None:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        # 1. filename만 따로 빼서 for문 돌려서 json_list에 있는 것과 비교\n",
    "        img_name = img_path.split('/')\n",
    "        for json_list in label_list:\n",
    "            with open(json_list, 'r') as f:\n",
    "                json_data = json.load(f)\n",
    "                for i in range(0, len(json_data)):\n",
    "                    filename = json_data[i]['filename']\n",
    "                    if filename == img_name:\n",
    "                        mask = json_data[i]\n",
    "                        \n",
    "        \n",
    "        # area : box의 면적으로써 나중에 IOU구하려고 만든거.\n",
    "        x_min = mask['annot_A']['boxes']['minX']\n",
    "        x_max = mask['annot_A']['boxes']['maxX']\n",
    "        y_min = mask['annot_A']['boxes']['minY']\n",
    "        y_max = mask['annot_A']['boxes']['maxY']\n",
    "        boxes = [x_min, y_min, x_max, y_max]\n",
    "        boxes = torch.as_tensor(boxes, dtype = torch.float32)\n",
    "        \n",
    "        area = (boxes[3] - boxes[1]) * (boxes[2] - boxes[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
